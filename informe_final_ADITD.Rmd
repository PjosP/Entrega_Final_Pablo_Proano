---
title: "Entrega_Final_PP"
author: "Pablo Proaño"
date: "2025-12-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# **PROYECTO FINAL**
# Analítica de Datos Industriales para la Toma de Decisiones con Apoyo de AI (Curso ADI&TD-IA) 

## Datos del Estudiante:
**Nombre:** Pablo Proaño

**mail:** pablo.proano@epn.edu.ec

**Telf:** +593 98 244 0935

## Descripción del Proyecto

El presente proyecto tiene como objetivo analizar un conjunto de datos correspondiente a operaciones de importación registradas por el Servicio Nacional de Aduana del Ecuador (SENAE), específicamente del conjunto denominado SENAE_Importaciones Régimen General, el cual contiene el detalle de las importaciones por fecha de ingreso de la Declaración Aduanera de Importación (DAI) con estado de salida autorizada. La base de datos, disponible en formato CSV y actualizada a diciembre de 2025, es utilizada para realizar procesos de carga, limpieza, descripción estadística y visualización de variables relacionadas con valor, peso, cantidades e impuestos.

## Descripción de la Base  de Datos

La base de datos utilizada en este proyecto corresponde al conjunto SENAE_Importaciones Régimen General, publicado por el Servicio Nacional de Aduana del Ecuador (SENAE), y contiene información detallada de las operaciones de importación registradas mediante la Declaración Aduanera de Importación (DAI) con estado de salida autorizada. El conjunto de datos se presenta en formato CSV y está compuesto por variables de tipo categórico y numérico. 

## Objetivo del Proyecto

Para el desarrollo del proyecto se consideran como **variables de entrada** aquellas asociadas a la información conocida al arribo de la mercancía a Aduana, tales como SUBPARTIDA, PAIS_ORIGEN, REGIMEN, PESO_NETO, FOB, FLETE, SEGURO, CANTIDAD_FISICA y CANTIDAD_COMERCIAL. **Como variables de salida** se definen los principales tributos calculados por la autoridad aduanera, entre ellos ADVALOREM, ICE, FODINFA, SALVAGUARDIA e IVA. Si bien estos valores se determinan mediante ecuaciones, formulas , tablas arancelarias y normativa específica, el objetivo del proyecto es **desarrollar un modelo basado en datos** que permita estimar dichos tributos aun sin conocer explícitamente estas ecuaciones, utilizando únicamente la información histórica contenida en la base de datos. 

## Carga y tratamiento de Datos
En esta sección cargamos los datos de la base que conseguimos para este trabajo.
```{r}
library(readr)
aduana  <- read_delim("https://raw.githubusercontent.com/PjosP/Entrega_Final_Pablo_Proano/refs/heads/main/base_aduana_10.csv", 
    delim = "|", escape_double = FALSE, trim_ws = TRUE)
head(aduana)
```

Vamos a revisar las dimenciones de la base de datos:
```{r}
dim(aduana)
```
Vamos a ver de que tipo son los campos de la base de datos:
```{r}
sapply(aduana, class)
```

Vamos a revisar si existen elementos en blanco o elementos duplicados:
```{r}
anyNA(aduana)
anyDuplicated(aduana)
```
Podemos ver que no hay celdas en blanco ni duplicadas.

La base de datos tiene algunas columnas que no son relevantes para nuestro estudio, por lo que vamos a crear una nueva base solo con las columnas que por ahora pensamos que son relevantes y lo vamos a almacenar en una base de datos que se llame **base_seleccionada**:

```{r}
# Definimos las variables de entrada
vars_entrada <- c(
  "REGIMEN", "SUBPARTIDA", "PAIS_ORIGEN", "CONVENIO_INTERNACIONAL",
  "PESO_NETO", "CANTIDAD_FISICA", "CANTIDAD_COMERCIAL",
  "TIPO_UNIDAD_FISICA", "TIPO_UNIDAD_COMERCIAL",
  "FOB", "FLETE", "SEGURO", "CIF"
)

# Definimos las variables de salida
vars_salida <- c(
  "ADVALOREM","ICE_ADVALOREM",
  "FODINFA", "IVA"
)

# Unimos las variables seleccionadas
vars_seleccionadas <- c(vars_entrada, vars_salida)

# Creamos la nueva base de datos
base_seleccionada <- aduana[, vars_seleccionadas]

# Verificación básica
dim(base_seleccionada)
```

## Analisis multivariante

Para saber si nuestro proyecto es Viable, voy a obtener la matriz de acrianzaras, para analizar si las variables están relacionadas y podría predecir unas en función de otras.

Sin embargo, previo a esto voy a reemplazar las filas que tienen texto por números, y voy a almacenar los resultados en una variable llamada **base_numerica** 

```{r}
# Se identificaron automáticamente las columnas que son de tipo carácter (texto)
vars_char <- names(base_seleccionada)[sapply(base_seleccionada, is.character)]

# Se creó una copia de la base original para trabajar con la versión numérica
base_numerica <- base_seleccionada

# Se transformaron las variables categóricas a valores numéricos mediante codificación de factores
base_numerica[vars_char] <- lapply(base_numerica[vars_char], function(x) {
  as.numeric(as.factor(x))
})

# Se verificó el tipo de dato de todas las columnas luego de la transformación
sapply(base_numerica, class)

```
**Nota:** Yo solía hacer esto a mano, investigando en Internet, vi que había dos formas automáticas de hacerlo, la primera usando el método de factores y la segunda usando el método "One-Hot Encoding", la primera sirve para modelos basados en árboles y métodos de clasificación que no dependen de relaciones lineales, como voy a usar random forest en mi proyecto decidí usar esa para no hacer mas grande la base. 


Ahora voy a normalizar la base y la voy a guardar en una nueva base de datos llamada **base_normalizada**
```{r}
# Función de normalización Min-Max
normalizar_minmax <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

# Aplicación de la normalización a todas las columnas
base_normalizada <- as.data.frame(
  lapply(base_numerica, normalizar_minmax)
)

# Verificación
summary(base_normalizada)


```


Ahora voy a calcular la matriz de covarianzas a partir de la base de datos normalizada, con el fin de analizar el grado de variación conjunta entre las variables de entrada y salida, y evaluar su relación estadística previa a la construcción del modelo.

```{r}
# Se calculó la matriz de covarianzas de la base de datos normalizada
matriz_covarianzas <- cov(base_normalizada)

# Se visualiza la matriz de covarianzas
matriz_covarianzas

```

Esta matriz, me suele parecer un poco confusa, por lo que personalmente uso la matriz de correlaciones:

```{r}
# Se calculó la matriz de covarianzas de la base de datos normalizada
matriz_correlacion <- cor(base_normalizada)

# Se visualiza la matriz de covarianzas
matriz_correlacion
```



Voy a representar la matriz de correlaciones usando un mapa de calor, para analizar de forma visual la intensidad y el signo de la relación entre las variables de entrada y salida. Este gráfico facilitó la identificación de dependencias fuertes, débiles y relaciones inversas entre variables.
```{r}
library(corrplot)
# Se generó el gráfico de correlación
corrplot(matriz_correlacion, method = "color", type = "upper")
```

**Nota:** Tuve que instalar la librería "corrplot"

Para ver los resultados por separado, voy a generar gráficos de barras para cada una de las salidas, quiero ver cuales de las variables de entrada tienen mayor impacto en las salidas.

Esto lo hago por que no un gran numero de variables de entrada y no quiero usarlas todas, solo las 4 mas relevantes.

**Para el IVA:**
```{r}
# Se extrajo la correlación de IVA con todas las variables de entrada
cor_iva <- matriz_correlacion[vars_entrada, "IVA"]

# Se generó el gráfico de barras de las correlaciones
barplot(cor_iva,
        las = 2,                 # rota etiquetas del eje X
        main = "Correlación de IVA con las variables de entrada",
        ylab = "Coeficiente de correlación",
        xlab = "Variables de entrada")

```


**Para el FODINFA:**
```{r}
cor_FODINFA <- matriz_correlacion[vars_entrada, "FODINFA"]

# Se generó el gráfico de barras de las correlaciones
barplot(cor_FODINFA,
        las = 2,                 # rota etiquetas del eje X
        main = "Correlación de FODINFA con las variables de entrada",
        ylab = "Coeficiente de correlación",
        xlab = "Variables de entrada")

```


**Para el ADVALOREM:**
```{r}
cor_ADVALOREM <- matriz_correlacion[vars_entrada, "ADVALOREM"]

# Se generó el gráfico de barras de las correlaciones
barplot(cor_ADVALOREM,
        las = 2,                 # rota etiquetas del eje X
        main = "Correlación de ADVALOREM con las variables de entrada",
        ylab = "Coeficiente de correlación",
        xlab = "Variables de entrada")

```

**Para el ICE_ADVALOREM:**
```{r}
cor_ICE_ADVALOREM <- matriz_correlacion[vars_entrada, "ICE_ADVALOREM"]

# Se generó el gráfico de barras de las correlaciones
barplot(cor_ICE_ADVALOREM,
        las = 2,                 # rota etiquetas del eje X
        main = "Correlación de ICE_ADVALOREM con las variables de entrada",
        ylab = "Coeficiente de correlación",
        xlab = "Variables de entrada")

```

## Resultados

A partir del análisis de correlación se observa que, para la salida **IVA**, las variables de entrada con mayor impacto son:

- `FLETE`
- `FOB`
- `CIF`
- `TIPO_UNIDAD_COMERCIAL`

Para la salida **FODINFA**, las variables de entrada de mayor influencia son:

- `FLETE`
- `PESO_NETO`
- `CIF`
- `FOB`

Finalmente, para las salidas **ADVALOREM** e **ICE_ADVALOREM**, las variables de entrada más relevantes son:

- `FLETE`
- `FOB`
- `CIF`
- `REGIMEN`

De manera general, se puede concluir que las variables de entrada **`FLETE`, `FOB` y `CIF`** presentan el mayor impacto sobre todas las salidas analizadas, mientras que una cuarta variable (como `TIPO_UNIDAD_COMERCIAL`, `PESO_NETO` o `REGIMEN`) aporta información adicional específica dependiendo de cada tributo.

## Resultados del análisis multivariable

Como resultado del estudio, se analizó el impacto de las variables de entrada sobre las salidas del modelo, identificando aquellas con mayor relevancia para la predicción de los tributos. De esta forma, se pasó de considerar inicialmente **13 variables de entrada** a trabajar únicamente con **3 variables principales** (`FLETE`, `FOB` y `CIF`).

En la siguiente etapa se generarán **cuatro conjuntos de datos**, uno para cada variable de salida, en los cuales las tres primeras columnas corresponderán a las variables de entrada seleccionadas y la última columna a la salida específica de cada modelo.



